---
title: "Hail - (4) Hail Table"
header:
  teaser: https://repository-images.githubusercontent.com/45069467/17243d00-7409-11ea-8faa-f09d532a9e98
date: 2021-07-07T13:00:00+09:00
categories:
  - Hail
tags:
  - Hail
  - Spark
  - Practice
  - Basic
---

## 1. Hail Table

Hail에서 `Table`은 우리가 흔하게 알고 있는 SQL의 table, pandas 또는 R의 Dataframe 등과 매우 유사하다고 보시면 됩니다. row field(column)마다 type(string, int32, array 등)이 지정되어 있는 schema에 따라 데이터가 여러 행으로 구성되어 있습니다. 차이가 존재하다면 row fields 이외에 global fields가 존재한다는 것과 Spark의 데이터처럼 partition으로 나뉘어져 있다는 것입니다. global fields는 Table에 대한 전체적인 메타 정보를 저장할 수 있다는 것이 전부입니다. 크게 어렵지 않죠? partition으로 데이터가 나뉘어져 있는 이유는 병렬처리를 쉽게 하기 위함인데, partition에 관해서는 뒤에서 자세히 다루겠습니다.

그럼 Hail Table을 읽고 쓰는 방법부터 하나씩 알아보도록 할까요?

### 1) 읽기 (Read or Import)

우선 데이터를 Table 형태로 불러오는 것부터 시작하겠습니다.
이미 Hail Table로 저장이 되어 있다면 불러오는 것은 간단합니다. `read_table` 함수로 말이죠.

```python
import hail as hl
ht = hl.read_table('path/to/hail_table.ht')
```

하지만 대부분의 데이터는 얻게 되는 경로는 텍스트 파일일 가능성이 높습니다. 따라서 처음에는  `import_table` 함수를 자주 쓰게 되죠. 유용한 parameter가 많기 때문에 자세히 보도록 하겠습니다.

```python
hail.methods.import_table(paths, key=None, min_partitions=None, impute=False, 
no_header=False, comment=(), delimiter='\t', missing='NA', types={}, 
quote=None, skip_blank_lines=False, force_bgz=False, filter=None, 
find_replace=None, force=False, source_file_field=None)
```

key와 partition에 대해서는 조금 있다가 살펴보기로 하고 우선 `impute`에 대해서 설명하겠습니다. 기본값은 `impute=False`인데 모든 data type을 `str`으로 간주하여 불러들이게 됩니다. `impute=True`로 설정하게 되면 Hail이 알아서 field의 type을 유추하여 schema를 구성하게 됩니다. 가지고 있는 데이터 type에 숫자가 많은 경우에는 유용한 parameter가 되겠죠.

몇몇 parameter가 어떻게 사용되는지는 예를 들고 넘어가겠습니다. import하려는 파일의 header가 존재하지 않을 때, `no_header=True`로 설정하면 임의로 field name(f0, f1, … fN)을 정하고 텍스트 파일의 첫째 행부터 불러들입니다. 또한 만약 파일의 구분자가 `,`인 경우에는 `delimiter=','`으로 설정해주면 되고, 파일에 `NaN`이 missing value로 표기되어 있다면 `missing='NaN'`을 사용하면 됩니다. 그 외의 parameter도 거의 pandas나 R과 비슷하게 설정되어 있다는 것을 알 수 있습니다.

parameter 중 주의해야 할 것이 바로 `force_bgz`와 `force`입니다. 텍스트 파일의 경우 용량이 크다면 압축을 하게 되는데, Bioinformatics에서 주로 사용하는 압축 포맷이 bgz입니다. 그런데 bgz가 조금 간사한 게 확장자가 `gz`로 둔갑하여 헷갈릴 때가 많습니다. 파일의 확장자가 `bgz`이면 import할 때 이를 자동으로 인식하여 불러들이지만, 확장자가 `gz`인 경우에는 이를 인식하지 못하거든요. 이때 `force_bgz=True` 설정을 통해 bgz 압축 파일임을 인식하도록 할 수 있습니다. 실제로 gz 압축 파일이면 어떻게 해야 할까? `force=True`를 이용해서 불러들이면 되지만 1개의 core만을 사용하기 떄문에 상당히 비효율적입니다. 따라서 gz 압축 파일인 경우에는 압축을 `gunzip`이나 `unpigz`(multi thread를 사용하여 속도가 빠름)를 통해 압축을 먼저 풀어주고 읽는 것을 추천합니다.

(작성중...)

Reference
---
- [https://hail.is/docs/0.2/overview/table.html](https://hail.is/docs/0.2/overview/table.html)


[1]:https://hail.is/docs/0.2/tutorials-landing.html
[2]:https://spark.apache.org/docs/3.1.1/configuration.html